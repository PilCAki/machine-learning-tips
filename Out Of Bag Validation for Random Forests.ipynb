{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da53080b",
   "metadata": {},
   "source": [
    "# The Hidden Validation Set You Might Not Be Using\n",
    "\n",
    "I love Random Forests. Really, I love all decision tree based models.  The concept of learning by partitioning is simple and intuitive and is easy to reason about when you’re trying to understand how a model might be “seeing” your data.\n",
    "\n",
    "For me, unless it’s not a good match for the dataset, a Random Forest is the way I like to start playing around with a dataset.\n",
    "\n",
    "One of the reasons is that some random forest implementations have a built-in validation set of sorts.  If you’re not familiar with “out of bag” validation, it’s an excellent addition to your ML development toolkit that I find is underutilized.  In fact – I almost never run into anybody else who regularly uses it!\n",
    "\n",
    "Check out this notebook in which we explore how the out-of-bag validation can speed up your workflow and potentially even give you a more accurate estimate of model performance than your k-fold cross-validation at a fraction of the computational cost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa7671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6547c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = dict(n_jobs=-1, n_estimators=256, min_samples_leaf=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714bc33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.032432</td>\n",
       "      <td>-0.013066</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>-0.017611</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>-0.014728</td>\n",
       "      <td>-0.014885</td>\n",
       "      <td>-0.005247</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>-0.008661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007763</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>-0.017136</td>\n",
       "      <td>-0.025479</td>\n",
       "      <td>-0.038388</td>\n",
       "      <td>-0.032405</td>\n",
       "      <td>-0.004957</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>-0.016520</td>\n",
       "      <td>-1.007347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008624</td>\n",
       "      <td>-0.032773</td>\n",
       "      <td>-0.020031</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>-0.006798</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>-0.040737</td>\n",
       "      <td>0.025638</td>\n",
       "      <td>-0.004040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031387</td>\n",
       "      <td>-0.014356</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>16.710669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015039</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>0.031771</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.015583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001197</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>-0.032698</td>\n",
       "      <td>-0.021573</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>-0.015747</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.021787</td>\n",
       "      <td>-4.883995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>-0.031028</td>\n",
       "      <td>-0.029758</td>\n",
       "      <td>-0.040502</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.017631</td>\n",
       "      <td>-0.034498</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>-0.009699</td>\n",
       "      <td>-0.007910</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>-0.048658</td>\n",
       "      <td>-0.008468</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>-3.864474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>-0.012750</td>\n",
       "      <td>-0.013199</td>\n",
       "      <td>-0.006064</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.023851</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>-0.001793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>-0.000769</td>\n",
       "      <td>-0.037190</td>\n",
       "      <td>0.039113</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>-0.007129</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>-0.020894</td>\n",
       "      <td>6.945772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.032432 -0.013066  0.004673 -0.017611  0.035532 -0.014728 -0.014885   \n",
       "1  0.008624 -0.032773 -0.020031  0.020145 -0.006798  0.003736  0.023822   \n",
       "2 -0.015039  0.034703  0.031771  0.001136 -0.000144  0.041739 -0.010032   \n",
       "3  0.009395  0.024268 -0.031028 -0.029758 -0.040502  0.029972  0.011669   \n",
       "4  0.003794  0.009415  0.006692 -0.012750 -0.013199 -0.006064  0.015940   \n",
       "\n",
       "          7         8         9  ...        21        22        23        24  \\\n",
       "0 -0.005247  0.003580 -0.008661  ... -0.007763  0.016018 -0.017136 -0.025479   \n",
       "1 -0.040737  0.025638 -0.004040  ... -0.031387 -0.014356  0.001716  0.038014   \n",
       "2  0.005467  0.003280  0.015583  ... -0.001197  0.028461 -0.032698 -0.021573   \n",
       "3  0.017631 -0.034498  0.003571  ...  0.005521 -0.001306 -0.009699 -0.007910   \n",
       "4  0.023851  0.017628 -0.001793  ...  0.010429 -0.000769 -0.037190  0.039113   \n",
       "\n",
       "         25        26        27        28        29     target  \n",
       "0 -0.038388 -0.032405 -0.004957 -0.005976 -0.016520  -1.007347  \n",
       "1  0.016288  0.008245 -0.004310  0.001984  0.016031  16.710669  \n",
       "2  0.013873  0.024355 -0.015747  0.005714  0.021787  -4.883995  \n",
       "3  0.025553 -0.048658 -0.008468  0.045984  0.004110  -3.864474  \n",
       "4  0.005426 -0.007129  0.001969  0.004865 -0.020894   6.945772  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_toy_dataset(n_train):\n",
    "    # Generating an unbalanced dataset\n",
    "    X, y = make_regression(\n",
    "        n_samples=n_train,\n",
    "        n_features=30,\n",
    "        n_informative=5,\n",
    "        effective_rank=12,\n",
    "        tail_strength=0.5,\n",
    "        noise=10.0,\n",
    "        random_state=42\n",
    "    )\n",
    "    df = pd.DataFrame(X)\n",
    "    df.columns = df.columns.astype(str)\n",
    "    _X = df.columns\n",
    "    _y = 'target'\n",
    "    df[_y] = y\n",
    "    return df, _X, _y\n",
    "\n",
    "df, _X, _y = generate_toy_dataset(n_train=1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd2fa0",
   "metadata": {},
   "source": [
    "# Bootstrapping and the Out of Bag Sample\n",
    "\n",
    "By default in scikit-learn, the Random Forest Regressor uses boostrap sampling.  That is, if you feed in \"n\" samples, every decision tree in the forest is trained on \"n\" samples chosen with replacement from the original \"n\".  \n",
    "\n",
    "Since the sampling happens with replacement, there will almost always be some samples left out of training on each tree.  Those rows are described as being \"out of bag\".\n",
    "\n",
    "The \"out of bag\" sample is interesting because it has the properties of a randomly selected validation set.  For each estimator added to the forest we have a \"free\" validation set sitting there which can be used in a manner similar to other forms of validation like \"leave one out\" or \"k-fold cross validation\".\n",
    "\n",
    "# oob_prediction\n",
    "\n",
    "We can form a prediction for the out of bag samples simply by feeding them into the decision tree that was trained during the round in which they were left out of training.\n",
    "\n",
    "These predictions are generated for each estimator, so in general each sample will have many out-of-bag predictions.\n",
    "\n",
    "The standard way of producing a prediction from a random forest is to feed a sample into each decision tree, get a prediction from each, and then average all of the predictions together.In a similar way, we can form an \"out-of-bag prediction\" for each sample in the training set by averaging together all of the individual out-of-bag predictions for that sample.  \n",
    "\n",
    "Since a given sample was never involved in the training of the tree that produces its out of bag prediction, the out-of-bag prediction can provide an estimate of generalization to unseen samples. In fact, it can be proven that the out-of-bag prediction is in general a *slightly pessimistic* evaluation of generalization performance.\n",
    "\n",
    "# The oob_prediction is like having a \"free\" set of cross-validation predictions\n",
    "\n",
    "The best thing about the oob_prediction is that it comes \"for free\" (small computational cost) as long as you ask for it, simply by specifying \"oob_score=True\". \n",
    "\n",
    "Do that and train the model and you'll be given access to \"oob_prediction\" which you can use to compute out-of-bag statistics which are very similar to cross validation statistics.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4be54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=20, n_estimators=256, n_jobs=-1,\n",
       "                      oob_score=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestRegressor(oob_score=True, **rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd2b55",
   "metadata": {},
   "source": [
    "# Compare oob to xval\n",
    "\n",
    "I'd like to argue that OOB Validation is simply generally better than KFold Cross Validation\n",
    "\n",
    "Why it's better:\n",
    "- it's easier and simpler to code up. \n",
    "- it's more precise (performance metric estimates have less variation)\n",
    "- train only 1 model instead of k models.  It's k times faster!  really it's k+1 times faster!\n",
    "\n",
    "In addition, there are downstream tasks like stacking, calibration, and potentially more - which are easier to do with OOB predictions than with a kfold-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f3f3c",
   "metadata": {},
   "source": [
    "# The code is simpler than kfold\n",
    "\n",
    "The code is just easier to write.  I don't know about you - but for me there's always a little bit of mental overhead or boilerplate in setting up a kfold loop or using a cross-val convenience wrapper.  OOB just totally eliminates that.\n",
    "\n",
    "No loops, no cross-val wrappers - just a single extra param and you've got your OOB predictions ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f6e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oob_mse(additional_rf_params={}):\n",
    "    model = RandomForestRegressor(oob_score=True, **{**rf_params, **additional_rf_params})\n",
    "    P = model.fit(df[_X], df[_y]).oob_prediction_ #boom - one and done\n",
    "    return mean_squared_error(P, df[_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbf9940",
   "metadata": {},
   "source": [
    "### Compare to Kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a4cd0",
   "metadata": {},
   "source": [
    "Compare to using \"KFold\" + manually indexing folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e38131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def kfold_mse(n_folds):\n",
    "    mses = []\n",
    "    for train_index, val_index in KFold(n_splits=n_folds, random_state=None, shuffle=True).split(df):\n",
    "        X_train = df.loc[train_index, _X]\n",
    "        y_train = df.loc[train_index, _y]\n",
    "        X_val   = df.loc[val_index, _X]\n",
    "        y_val   = df.loc[val_index, _y]\n",
    "        model = RandomForestRegressor(oob_score=False, **rf_params)\n",
    "        P_val = model.fit(X_train, y_train).predict(X_val)\n",
    "        mses.append(mean_squared_error(P_val, y_val))\n",
    "    return np.mean(mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882553ae",
   "metadata": {},
   "source": [
    "There's a lot to track here in terms of indexing etc. \n",
    "\n",
    "To be fair, there are things you can do with this approach that you can't do with the OOB technique.  For example: stratified sampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9a8824",
   "metadata": {},
   "source": [
    "### Compare to Xval Convenience Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59aea97",
   "metadata": {},
   "source": [
    "Or compare to scikit-learn's cross validation convenience functions which can be less elegant and less flexible than the OOB approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8d8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "def sklearn_cv_mse(n_folds):\n",
    "    mse = make_scorer(mean_squared_error)\n",
    "    model = RandomForestRegressor(oob_score=False, **rf_params)\n",
    "    cv_results = cross_validate(model, df[_X], df[_y], cv=n_folds, scoring=mse) \n",
    "    return np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e747d",
   "metadata": {},
   "source": [
    "In this example you need to remember to make your own \"mean_squared_error\" scorer using \"make_scorer\" or you have to feed in \"neg_mean_squared_error\" which results in the output score being negative.\n",
    "\n",
    "It's a bit awkward!  \n",
    "\n",
    "I went with making my own scorer to avoid any downstream effects from potentially forgetting to negate the output of cv_results['test_score'] (for example - accidentally selecting the worst model instead of the best model from a hyperparam search).\n",
    "\n",
    "Even the somewhat streamlined cross_validate convenience function isn't as clean, simple, and terse as the OOB validation method.\n",
    "\n",
    "It's not a huge difference on its own but efficiencies in code add up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c79fbe",
   "metadata": {},
   "source": [
    "# OOB Validation is more precise than kfold cross-validation\n",
    "\n",
    "Let's measure the precision of out of bag validation compared to kfold cross validation .\n",
    "\n",
    "We'll do this by repeatedly running en experiment in which we compute a validation statistic (mean squared error) and then analyze the variation of that statistic across repeated runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11f4fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c5cee3d16343dc9756fb65f979b974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72309efaef2c4f93aa304d2a582c21a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbe26fc3afa4f0a9f7ac8f405b1d439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1998ae01094f0d9774c40802c6e382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470058df81c543828a3d064aa74333aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def oob_vs_kfold():\n",
    "    n_experiment_rounds = 50\n",
    "    \n",
    "    oob_mses      = [oob_mse() for _ in tqdm(range(n_experiment_rounds))]\n",
    "    kfold_mses_3  = [kfold_mse(n_folds=3)  for _ in tqdm(range(n_experiment_rounds))]\n",
    "    kfold_mses_5  = [kfold_mse(n_folds=5)  for _ in tqdm(range(n_experiment_rounds))]\n",
    "    kfold_mses_10 = [kfold_mse(n_folds=10) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    kfold_mses_20 = [kfold_mse(n_folds=20) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    \n",
    "    \n",
    "    mses = pd.DataFrame(dict(oob=oob_mses, \n",
    "                             kfold_3=kfold_mses_3,\n",
    "                             kfold_5=kfold_mses_5,\n",
    "                             kfold_10=kfold_mses_10,\n",
    "                             kfold_20=kfold_mses_20\n",
    "                            ))\n",
    "    \n",
    "    return mses\n",
    "    \n",
    "mses = oob_vs_kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e424af1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oob</th>\n",
       "      <th>kfold_3</th>\n",
       "      <th>kfold_5</th>\n",
       "      <th>kfold_10</th>\n",
       "      <th>kfold_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102.110971</td>\n",
       "      <td>103.060098</td>\n",
       "      <td>101.085444</td>\n",
       "      <td>102.073909</td>\n",
       "      <td>101.998807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.022619</td>\n",
       "      <td>102.709733</td>\n",
       "      <td>102.639982</td>\n",
       "      <td>102.497740</td>\n",
       "      <td>101.651983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101.648983</td>\n",
       "      <td>103.129879</td>\n",
       "      <td>102.558203</td>\n",
       "      <td>102.213468</td>\n",
       "      <td>102.560787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102.594244</td>\n",
       "      <td>102.191084</td>\n",
       "      <td>102.127463</td>\n",
       "      <td>102.531201</td>\n",
       "      <td>101.694535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.965452</td>\n",
       "      <td>102.226510</td>\n",
       "      <td>102.920187</td>\n",
       "      <td>102.394298</td>\n",
       "      <td>100.974318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102.371856</td>\n",
       "      <td>103.008761</td>\n",
       "      <td>100.967999</td>\n",
       "      <td>102.697971</td>\n",
       "      <td>102.574012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101.722242</td>\n",
       "      <td>102.197245</td>\n",
       "      <td>102.381607</td>\n",
       "      <td>102.302552</td>\n",
       "      <td>101.819739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>102.018081</td>\n",
       "      <td>105.210680</td>\n",
       "      <td>101.801356</td>\n",
       "      <td>102.434838</td>\n",
       "      <td>101.776994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>102.551499</td>\n",
       "      <td>103.298293</td>\n",
       "      <td>103.370401</td>\n",
       "      <td>101.610504</td>\n",
       "      <td>101.526712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>102.106540</td>\n",
       "      <td>101.540208</td>\n",
       "      <td>102.179012</td>\n",
       "      <td>101.872759</td>\n",
       "      <td>102.295598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>102.094725</td>\n",
       "      <td>102.752445</td>\n",
       "      <td>102.942691</td>\n",
       "      <td>102.907542</td>\n",
       "      <td>101.910669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101.910147</td>\n",
       "      <td>102.303413</td>\n",
       "      <td>101.195655</td>\n",
       "      <td>101.762890</td>\n",
       "      <td>102.195198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101.908656</td>\n",
       "      <td>102.805402</td>\n",
       "      <td>101.485857</td>\n",
       "      <td>101.848803</td>\n",
       "      <td>101.218851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>101.983103</td>\n",
       "      <td>102.208917</td>\n",
       "      <td>101.684833</td>\n",
       "      <td>102.578327</td>\n",
       "      <td>101.035174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102.130119</td>\n",
       "      <td>102.178570</td>\n",
       "      <td>102.591208</td>\n",
       "      <td>101.317443</td>\n",
       "      <td>102.272722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>102.265778</td>\n",
       "      <td>102.339433</td>\n",
       "      <td>100.699402</td>\n",
       "      <td>101.746690</td>\n",
       "      <td>101.368011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>102.216774</td>\n",
       "      <td>100.666758</td>\n",
       "      <td>101.407251</td>\n",
       "      <td>102.251407</td>\n",
       "      <td>101.455838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>102.524140</td>\n",
       "      <td>101.030842</td>\n",
       "      <td>103.007238</td>\n",
       "      <td>101.291618</td>\n",
       "      <td>102.353384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>102.228572</td>\n",
       "      <td>103.111783</td>\n",
       "      <td>102.070195</td>\n",
       "      <td>101.914389</td>\n",
       "      <td>102.421850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>102.433270</td>\n",
       "      <td>101.231568</td>\n",
       "      <td>103.046637</td>\n",
       "      <td>101.800927</td>\n",
       "      <td>101.680058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>102.192031</td>\n",
       "      <td>102.499468</td>\n",
       "      <td>101.017482</td>\n",
       "      <td>103.011985</td>\n",
       "      <td>102.129058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>102.208832</td>\n",
       "      <td>102.120974</td>\n",
       "      <td>102.460356</td>\n",
       "      <td>101.981901</td>\n",
       "      <td>102.137120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>101.887973</td>\n",
       "      <td>102.258217</td>\n",
       "      <td>99.978404</td>\n",
       "      <td>102.461348</td>\n",
       "      <td>101.457484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>101.780030</td>\n",
       "      <td>101.389072</td>\n",
       "      <td>102.156337</td>\n",
       "      <td>102.426303</td>\n",
       "      <td>101.884890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>101.919042</td>\n",
       "      <td>101.168557</td>\n",
       "      <td>102.095233</td>\n",
       "      <td>101.842267</td>\n",
       "      <td>101.658817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>102.187650</td>\n",
       "      <td>101.424842</td>\n",
       "      <td>103.116585</td>\n",
       "      <td>102.671203</td>\n",
       "      <td>101.599091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>102.452425</td>\n",
       "      <td>101.855004</td>\n",
       "      <td>101.655118</td>\n",
       "      <td>102.509831</td>\n",
       "      <td>101.735125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>102.517854</td>\n",
       "      <td>102.747495</td>\n",
       "      <td>102.087995</td>\n",
       "      <td>101.689374</td>\n",
       "      <td>102.019974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>102.420631</td>\n",
       "      <td>102.513207</td>\n",
       "      <td>101.062620</td>\n",
       "      <td>102.281319</td>\n",
       "      <td>101.665353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>101.790487</td>\n",
       "      <td>103.321863</td>\n",
       "      <td>102.303209</td>\n",
       "      <td>101.876142</td>\n",
       "      <td>102.056253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>102.282459</td>\n",
       "      <td>102.654753</td>\n",
       "      <td>102.580010</td>\n",
       "      <td>101.528297</td>\n",
       "      <td>101.746445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>102.019947</td>\n",
       "      <td>101.815451</td>\n",
       "      <td>102.110334</td>\n",
       "      <td>101.693791</td>\n",
       "      <td>101.275457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>101.964630</td>\n",
       "      <td>102.237204</td>\n",
       "      <td>103.226236</td>\n",
       "      <td>101.447166</td>\n",
       "      <td>101.869648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>102.228323</td>\n",
       "      <td>103.831092</td>\n",
       "      <td>102.858889</td>\n",
       "      <td>102.821199</td>\n",
       "      <td>101.653196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>102.427824</td>\n",
       "      <td>103.580407</td>\n",
       "      <td>101.971249</td>\n",
       "      <td>101.738978</td>\n",
       "      <td>102.056547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>101.994526</td>\n",
       "      <td>101.990922</td>\n",
       "      <td>102.310503</td>\n",
       "      <td>101.235213</td>\n",
       "      <td>102.025988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>101.310872</td>\n",
       "      <td>99.941000</td>\n",
       "      <td>102.003077</td>\n",
       "      <td>101.374042</td>\n",
       "      <td>101.655893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>101.813087</td>\n",
       "      <td>100.494906</td>\n",
       "      <td>102.706359</td>\n",
       "      <td>102.416655</td>\n",
       "      <td>102.129623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>102.442616</td>\n",
       "      <td>102.099152</td>\n",
       "      <td>102.014143</td>\n",
       "      <td>100.864469</td>\n",
       "      <td>101.623800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>101.867727</td>\n",
       "      <td>103.473795</td>\n",
       "      <td>102.078956</td>\n",
       "      <td>102.701282</td>\n",
       "      <td>101.784385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>101.955273</td>\n",
       "      <td>102.298163</td>\n",
       "      <td>102.277157</td>\n",
       "      <td>102.370106</td>\n",
       "      <td>102.388098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>102.475231</td>\n",
       "      <td>102.628768</td>\n",
       "      <td>101.611301</td>\n",
       "      <td>101.333241</td>\n",
       "      <td>102.469612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>101.856389</td>\n",
       "      <td>101.695779</td>\n",
       "      <td>102.120157</td>\n",
       "      <td>102.337899</td>\n",
       "      <td>101.596373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>101.645609</td>\n",
       "      <td>102.277700</td>\n",
       "      <td>103.009839</td>\n",
       "      <td>101.536873</td>\n",
       "      <td>102.466595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>101.891757</td>\n",
       "      <td>102.413619</td>\n",
       "      <td>102.392708</td>\n",
       "      <td>102.308339</td>\n",
       "      <td>102.238594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>102.279299</td>\n",
       "      <td>103.352022</td>\n",
       "      <td>102.217661</td>\n",
       "      <td>101.980548</td>\n",
       "      <td>101.306654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>102.401177</td>\n",
       "      <td>100.616127</td>\n",
       "      <td>101.412197</td>\n",
       "      <td>103.613903</td>\n",
       "      <td>102.413818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>102.443737</td>\n",
       "      <td>102.390488</td>\n",
       "      <td>101.664091</td>\n",
       "      <td>102.355450</td>\n",
       "      <td>101.533053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>102.326838</td>\n",
       "      <td>101.785874</td>\n",
       "      <td>102.508361</td>\n",
       "      <td>102.415226</td>\n",
       "      <td>101.215457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>102.181636</td>\n",
       "      <td>102.181522</td>\n",
       "      <td>102.280995</td>\n",
       "      <td>102.820070</td>\n",
       "      <td>101.425318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           oob     kfold_3     kfold_5    kfold_10    kfold_20\n",
       "0   102.110971  103.060098  101.085444  102.073909  101.998807\n",
       "1   101.022619  102.709733  102.639982  102.497740  101.651983\n",
       "2   101.648983  103.129879  102.558203  102.213468  102.560787\n",
       "3   102.594244  102.191084  102.127463  102.531201  101.694535\n",
       "4   101.965452  102.226510  102.920187  102.394298  100.974318\n",
       "5   102.371856  103.008761  100.967999  102.697971  102.574012\n",
       "6   101.722242  102.197245  102.381607  102.302552  101.819739\n",
       "7   102.018081  105.210680  101.801356  102.434838  101.776994\n",
       "8   102.551499  103.298293  103.370401  101.610504  101.526712\n",
       "9   102.106540  101.540208  102.179012  101.872759  102.295598\n",
       "10  102.094725  102.752445  102.942691  102.907542  101.910669\n",
       "11  101.910147  102.303413  101.195655  101.762890  102.195198\n",
       "12  101.908656  102.805402  101.485857  101.848803  101.218851\n",
       "13  101.983103  102.208917  101.684833  102.578327  101.035174\n",
       "14  102.130119  102.178570  102.591208  101.317443  102.272722\n",
       "15  102.265778  102.339433  100.699402  101.746690  101.368011\n",
       "16  102.216774  100.666758  101.407251  102.251407  101.455838\n",
       "17  102.524140  101.030842  103.007238  101.291618  102.353384\n",
       "18  102.228572  103.111783  102.070195  101.914389  102.421850\n",
       "19  102.433270  101.231568  103.046637  101.800927  101.680058\n",
       "20  102.192031  102.499468  101.017482  103.011985  102.129058\n",
       "21  102.208832  102.120974  102.460356  101.981901  102.137120\n",
       "22  101.887973  102.258217   99.978404  102.461348  101.457484\n",
       "23  101.780030  101.389072  102.156337  102.426303  101.884890\n",
       "24  101.919042  101.168557  102.095233  101.842267  101.658817\n",
       "25  102.187650  101.424842  103.116585  102.671203  101.599091\n",
       "26  102.452425  101.855004  101.655118  102.509831  101.735125\n",
       "27  102.517854  102.747495  102.087995  101.689374  102.019974\n",
       "28  102.420631  102.513207  101.062620  102.281319  101.665353\n",
       "29  101.790487  103.321863  102.303209  101.876142  102.056253\n",
       "30  102.282459  102.654753  102.580010  101.528297  101.746445\n",
       "31  102.019947  101.815451  102.110334  101.693791  101.275457\n",
       "32  101.964630  102.237204  103.226236  101.447166  101.869648\n",
       "33  102.228323  103.831092  102.858889  102.821199  101.653196\n",
       "34  102.427824  103.580407  101.971249  101.738978  102.056547\n",
       "35  101.994526  101.990922  102.310503  101.235213  102.025988\n",
       "36  101.310872   99.941000  102.003077  101.374042  101.655893\n",
       "37  101.813087  100.494906  102.706359  102.416655  102.129623\n",
       "38  102.442616  102.099152  102.014143  100.864469  101.623800\n",
       "39  101.867727  103.473795  102.078956  102.701282  101.784385\n",
       "40  101.955273  102.298163  102.277157  102.370106  102.388098\n",
       "41  102.475231  102.628768  101.611301  101.333241  102.469612\n",
       "42  101.856389  101.695779  102.120157  102.337899  101.596373\n",
       "43  101.645609  102.277700  103.009839  101.536873  102.466595\n",
       "44  101.891757  102.413619  102.392708  102.308339  102.238594\n",
       "45  102.279299  103.352022  102.217661  101.980548  101.306654\n",
       "46  102.401177  100.616127  101.412197  103.613903  102.413818\n",
       "47  102.443737  102.390488  101.664091  102.355450  101.533053\n",
       "48  102.326838  101.785874  102.508361  102.415226  101.215457\n",
       "49  102.181636  102.181522  102.280995  102.820070  101.425318"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e93621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oob</th>\n",
       "      <th>kfold_3</th>\n",
       "      <th>kfold_5</th>\n",
       "      <th>kfold_10</th>\n",
       "      <th>kfold_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102.099474</td>\n",
       "      <td>102.285181</td>\n",
       "      <td>102.109004</td>\n",
       "      <td>102.113874</td>\n",
       "      <td>101.840059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.320546</td>\n",
       "      <td>0.930227</td>\n",
       "      <td>0.706919</td>\n",
       "      <td>0.546338</td>\n",
       "      <td>0.410853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>101.022619</td>\n",
       "      <td>99.941000</td>\n",
       "      <td>99.978404</td>\n",
       "      <td>100.864469</td>\n",
       "      <td>100.974318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>102.594244</td>\n",
       "      <td>105.210680</td>\n",
       "      <td>103.370401</td>\n",
       "      <td>103.613903</td>\n",
       "      <td>102.574012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             oob     kfold_3     kfold_5    kfold_10    kfold_20\n",
       "mean  102.099474  102.285181  102.109004  102.113874  101.840059\n",
       "std     0.320546    0.930227    0.706919    0.546338    0.410853\n",
       "min   101.022619   99.941000   99.978404  100.864469  100.974318\n",
       "max   102.594244  105.210680  103.370401  103.613903  102.574012"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses.agg(['mean', 'std', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b229841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAztklEQVR4nO3de1xUdf7H8ffI3eTiFSTB0IBE3aiMn0YWbqVJKWWPX7nZmtfkl4mKmtq266XCS6jUmthtUR+Z2sqS7uNnlLuirZm/8oKYkZnhJYXYyhiviHJ+f/RwNhR0ZhiYOfp6Ph7zeDRnvuc7n/Mdgrff851zLIZhGAIAADCpJu4uAAAAoD4IMwAAwNQIMwAAwNQIMwAAwNQIMwAAwNQIMwAAwNQIMwAAwNQIMwAAwNS83V1AQ6uurtbRo0cVGBgoi8Xi7nIAAIAdDMPQ8ePHFR4eriZNLj/3ctWHmaNHjyoiIsLdZQAAACccPnxY7dq1u2ybqz7MBAYGSvplMIKCgtxcDQAAsIfValVERITt7/jlXPVh5sKppaCgIMIMAAAmY88SERYAAwAAUyPMAAAAUyPMAAAAU7vq18wAAK4thmHo3LlzOn/+vLtLwWV4eXnJ29vbJZdNIcwAAK4aZ8+eVWlpqU6dOuXuUmCHpk2bqm3btvL19a1XP4QZAMBVobq6WiUlJfLy8lJ4eLh8fX25WKqHMgxDZ8+e1b///W+VlJQoOjr6ihfGuxzCDADgqnD27FlVV1crIiJCTZs2dXc5uIKAgAD5+Pjo4MGDOnv2rPz9/Z3uiwXAAICrSn3+hY/G5arPik8cAACYGmEGAACYmlvXzHz88cd6+eWXtX37dpWWliovL08PPfSQ7XXDMDRjxgy98cYbOnbsmP7rv/5Lr732mjp37uy+ogEApnPDlP9ttPc6MPuBRnuvC5KSkhQfH6+srKxGf29P4NaZmZMnT+rmm2/WwoULa3197ty5mj9/vhYuXKjPP/9cYWFhuu+++3T8+PFGrhQAAHgqt87M9O3bV3379q31NcMwlJWVpT/84Q8aMGCAJGnp0qUKDQ3Vu+++q1GjRjVmqQAAwEN57JqZkpISlZWVqXfv3rZtfn5+uvvuu7Vly5Y696usrJTVaq3xAADAk1VWViotLU1t2rSRv7+/7rzzTn3++ee21zdt2qSEhAT5+fmpbdu2mjJlis6dO1ejj3PnzumZZ55RSEiIWrZsqeeff16GYTT2obiFx15npqysTJIUGhpaY3toaKgOHjxY536zZs3SjBkzGrQ2AJKmBzvQtqLh6gCuAs8++6xyc3O1dOlStW/fXnPnzlWfPn30zTff6PTp00pOTtaQIUO0bNkyffXVVxo5cqT8/f01ffp0Wx9Lly7V8OHD9X//93/atm2bnnrqKbVv314jR45034E1Eo8NMxdcfPVGwzAue0XHqVOnKj093fbcarUqIiKiweoDAKA+Tp48qezsbC1ZssS29OLNN9/U+vXr9fbbb+vnn39WRESEFi5cKIvFoptuuklHjx7V5MmT9ac//cl2rZaIiAgtWLBAFotFsbGx2r17txYsWHBNhBmPPc0UFhYm6T8zNBeUl5dfMlvza35+fgoKCqrxAADAU+3fv19VVVVKTEy0bfPx8VFCQoKKi4tVXFysHj161PiHfGJiok6cOKHvvvvOtq179+412vTo0UP79u27Jm646bFhJioqSmFhYVq/fr1t29mzZ7Vp0ybdcccdbqwMAADXubCupa4zEbWdkahrn2uVW8PMiRMnVFhYqMLCQkm/LPotLCzUoUOHZLFYNG7cOGVkZCgvL09ffPGFhgwZoqZNm+rxxx93Z9kAALjMjTfeKF9fX23evNm2raqqStu2bVOnTp0UFxenLVu21FjMu2XLFgUGBur666+3bdu6dWuNfrdu3aro6Gh5eXk1/EG4mVvXzGzbtk29evWyPb+w1uXJJ5/UkiVL9Oyzz+r06dN6+umnbRfN++ijjxQYGOiukgEAcKnrrrtO//M//6NJkyapRYsWioyM1Ny5c3Xq1CkNHz5cp06dUlZWlsaMGaNnnnlGe/fu1bRp05Senl7j3kaHDx9Wenq6Ro0apR07dujPf/6z5s2b58YjazxuDTNJSUmX/dqYxWLR9OnTa6zWBgDAUe64Kq8jZs+ererqav3+97/X8ePH1a1bN3344Ydq3ry5mjdvrnXr1mnSpEm6+eab1aJFCw0fPlzPP/98jT4GDx6s06dPKyEhQV5eXhozZoyeeuopNx1R47IYV/mX0K1Wq4KDg1VRUcFiYMCV+Go2PMyZM2dUUlKiqKgo+fv7u7sc2OFyn5kjf789dgEwAACAPQgzAADA1AgzAADA1AgzAADA1AgzAADA1AgzAADA1AgzAADA1AgzAADA1AgzAADA1Nx6OwMAABqFI1esrvd7OX7F66SkJMXHxysrK6v2LqdPV3Z2tsrLy5WXl6eHHnrosv0dOHBAUVFR2rlzp+Lj42tts3HjRvXq1UvHjh1TSEiIwzV7EmZmAADwYMXFxZoxY4Zef/11lZaWqm/fvo1ew969e9WrVy+FhobK399fHTp00PPPP6+qqqpGr6U2zMwAAODB9u/fL0lKSUmRxWJxSw0+Pj4aPHiwbr31VoWEhGjXrl0aOXKkqqurlZGR4Zaafo2ZGQAAPEx+fr6Cg4PVoUMH9evXT5LUpEkTW5iprq7WzJkz1a5dO/n5+Sk+Pl75+fmX7XPdunWKiYlRQECAevXqpQMHDthdT4cOHTR06FDdfPPNat++vfr3769BgwbpX//6l9PH6EqEGQAAPMjKlSv16KOPatmyZSoqKlJOTo4kqbS0VKWlpZKkV155RfPmzVNmZqaKiorUp08f9e/fX/v27au1z8OHD2vAgAFKTk5WYWGhRowYoSlTpjhd4zfffKP8/HzdfffdTvfhSoQZAAA8xKJFi5Samqo1a9YoJSVFzZo1sy3ODQsLU1hYmCQpMzNTkydP1sCBAxUbG6s5c+ZcdgFxdna2OnTooAULFig2NlaDBg3SkCFDHK7vjjvukL+/v6Kjo9WzZ0/NnDnTySN1LdbMAADgAXJzc/X9999r8+bNSkhIqLOd1WrV0aNHlZiYWGN7YmKidu3aVes+xcXF6t69e401Nz169HC4xlWrVun48ePatWuXJk2apMzMTD377LMO9+NqhBkAADxAfHy8duzYoZycHN1+++1XXOx78euGYdS5j2EYLqkxIiJCkhQXF6fz58/rqaee0oQJE+Tl5eWS/p3FaSYAADxAx44dVVBQoDVr1mjMmDF1tgsKClJ4eLg2b95cY/uWLVvUqVOnWveJi4vT1q1ba2y7+LmjDMNQVVWVy4JSfTAzAwCAh4iJiVFBQYGSkpLk7e1d5xqYSZMmadq0aerYsaPi4+OVk5OjwsJCLV++vNb2qampmjdvntLT0zVq1Cht375dS5Yssbuu5cuXy8fHR127dpWfn5+2b9+uqVOn6rHHHpO3t/ujhPsrAACgoTlxVV53iY2N1YYNG5SUlCQvLy/17NnzkjZpaWmyWq2aMGGCysvLFRcXp7Vr1yo6OrrWPiMjI5Wbm6vx48dr0aJFSkhIUEZGhoYNG2ZXTd7e3pozZ46+/vprGYah9u3ba/To0Ro/fny9jtVVLIYnzA81IKvVquDgYFVUVCgoKMjd5QBXD0cuD2+iPyQwrzNnzqikpERRUVHy9/d3dzmww+U+M0f+frNmBgAAmBphBgCAa1zfvn3VrFmzWh+ecLuCK2HNDAAA17i33npLp0+frvW1Fi1aNHI1jiPMAABwjbv++uvdXUK9cJoJAACYGmEGAACYGqeZAA/wWuoGu9uOXvzbBquj69Kudrfd3WBVAIBjmJkBAACmRpgBAACmxmkmAMBVz5FTqPW1+0nHT8ImJSUpPj6+znsxTZ8+XdnZ2SovL1deXp4eeuihy/Z34MABRUVFaefOnYqPj6+1zcaNG9WrVy8dO3ZMISEhDtfsSZiZAQDAgxUXF2vGjBl6/fXXVVpaqr59+zZ6DQcOHJDFYrnkkZ+f3+i11IaZGQAAPNj+/fslSSkpKbJYLG6t5R//+Ic6d+5se+4pF9RjZgYAAA+Tn5+v4OBgdejQQf369ZMkNWnSxBZmqqurNXPmTLVr105+fn6Kj4+/4izJunXrFBMTo4CAAPXq1UsHDhxwuK6WLVsqLCzM9vD19XW4j4ZAmAEAwIOsXLlSjz76qJYtW6aioiLl5ORIkkpLS1VaWipJeuWVVzRv3jxlZmaqqKhIffr0Uf/+/bVv375a+zx8+LAGDBig5ORkFRYWasSIEZoyZYrDtfXv319t2rRRYmKiVq9e7fxBuhhhBgAAD7Fo0SKlpqZqzZo1SklJUbNmzWyLcy/MhkhSZmamJk+erIEDByo2NlZz5sy57ALi7OxsdejQQQsWLFBsbKwGDRqkIUOG2F1Xs2bNNH/+fK1evVrr1q3TPffco8cee0zvvPNOPY/YNVgzAwCAB8jNzdX333+vzZs3KyEhoc52VqtVR48eVWJiYo3tiYmJ2rVrV637FBcXq3v37jXW3PTo0cPu2lq1aqXx48fbnnfr1k3Hjh3T3Llz9cQTT9jdT0NhZgYAAA8QHx+v1q1bKycnR4ZhXLH9xYuBDcOoc4GwPf05qnv37nWe1mpshBkAADxAx44dVVBQoDVr1mjMmDF1tgsKClJ4eLg2b95cY/uWLVvUqVOnWveJi4vT1q1ba2y7+Lmjdu7cqbZt29arD1fhNBMAAB4iJiZGBQUFSkpKkre3d51rYCZNmqRp06apY8eOio+PV05OjgoLC7V8+fJa26empmrevHlKT0/XqFGjtH37di1ZssTuupYuXSofHx/dcsstatKkif7+97/r1Vdf1Zw5c5w4StcjzAAArnrOXJXXXWJjY7VhwwYlJSXJy8tLPXv2vKRNWlqarFarJkyYoPLycsXFxWnt2rWKjo6utc/IyEjl5uZq/PjxWrRokRISEpSRkaFhw4bZXdeLL76ogwcPysvLSzExMfrLX/7iEetlJMliNMSJNA9itVoVHBysiooKBQUFubscoFamvGt2ySH7O55e4UQ1gGPOnDmjkpISRUVFyd/f393lwA6X+8wc+fvNmhkAAGBqhBkAAK5xffv2VbNmzWp9ZGRkuLu8K2LNDAAA17i33npLp0+frvU1T7n/0uUQZgAAuMZdf/317i6hXjjNBAAATI0wAwAATI0wAwAATI0wAwAATI0wAwAATI0wAwCAmyUlJWncuHF1vj59+nSFhobKYrHo/fffv2J/Bw4ckMViUWFhYZ1tNm7cKIvFop9//tnhej0NX80GAFz1im+q/W7SDaHTV8Uu7a+4uFgzZsxQXl6eunfvrubNm7u0f3ucOXNGqamp2r59u4qLi/Xggw/WGqo2bdqk9PR07dmzR+Hh4Xr22WeVmpra4PUxMwMAgAfbv3+/JCklJUVhYWHy8/Nr9BrOnz+vgIAApaWl6d577621TUlJiZKTk9WzZ0/t3LlTzz33nNLS0pSbm9vg9RFmAADwMPn5+QoODlaHDh3Ur18/SVKTJk1ksVgkSdXV1Zo5c6batWsnPz8/xcfHKz8//7J9rlu3TjExMQoICFCvXr104MABu+u57rrrlJ2drZEjRyosLKzWNosXL1ZkZKSysrLUqVMnjRgxQsOGDVNmZqbd7+MswgwAAB5k5cqVevTRR7Vs2TIVFRUpJydHklRaWqrS0lJJ0iuvvKJ58+YpMzNTRUVF6tOnj/r37699+/bV2ufhw4c1YMAAJScnq7CwUCNGjNCUKVNcWvenn36q3r1719jWp08fbdu2TVVVVS59r4sRZgAA8BCLFi1Samqq1qxZo5SUFDVr1kwhISGSpLCwMNusSGZmpiZPnqyBAwcqNjZWc+bMUXx8vLKysmrtNzs7Wx06dNCCBQsUGxurQYMGaciQIS6tvaysTKGhoTW2hYaG6ty5c/rhhx9c+l4XYwEwAAAeIDc3V99//702b96shISEOttZrVYdPXpUiYmJNbYnJiZq165dte5TXFys7t27205TSVKPHj1cU/iv/Lp/STIMo9btrsbMDAAAHiA+Pl6tW7dWTk6OLQRcTm3Boa7QYE9/9RUWFqaysrIa28rLy+Xt7a2WLVs26Ht7dJg5d+6cnn/+eUVFRSkgIEAdOnTQzJkzVV1d7e7SAABwqY4dO6qgoEBr1qzRmDFj6mwXFBSk8PBwbd68ucb2LVu2qFOn2r+CHhcXp61bt9bYdvHz+urRo4fWr19fY9tHH32kbt26ycfHx6XvdTGPPs00Z84cLV68WEuXLlXnzp21bds2DR06VMHBwRo7dqy7ywMAwKViYmJUUFCgpKQkeXt717kGZtKkSZo2bZo6duyo+Ph45eTkqLCwUMuXL6+1fWpqqubNm6f09HSNGjVK27dv15IlSxyq7csvv9TZs2f1008/6fjx47YL8sXHx9veY+HChUpPT9fIkSP16aef6u2339aKFSsceh9neHSY+fTTT5WSkqIHHnhAknTDDTdoxYoV2rZtm5srAwCYiasvZNeQYmNjtWHDBiUlJcnLy0s9e/a8pE1aWpqsVqsmTJig8vJyxcXFae3atYqOjq61z8jISOXm5mr8+PFatGiREhISlJGRoWHDhtldV3Jysg4ePGh7fsstt0j6zymsqKgorVu3TuPHj9drr72m8PBwvfrqq3rkkUccOXynWIzGOJHmpNmzZ2vx4sX66KOPFBMTo127dql3797KysrS7373u1r3qaysVGVlpe251WpVRESEKioqFBQU1FilAw55LXWD3W1HL/5tg9XRdWlXu9vuLjlkf8fTK5yoBnDMmTNnVFJSoqioKPn7+7u7HNjhcp+Z1WpVcHCwXX+/PXpmZvLkyaqoqNBNN90kLy8vnT9/Xi+99FKdQUaSZs2apRkzZjRilUDjumHK/zZY34ENdMV3Ry8lb6Z/RQNwP49eALxq1Sq98847evfdd7Vjxw4tXbpUmZmZWrp0aZ37TJ06VRUVFbbH4cOHG7FiAADMp2/fvmrWrFmtj4yMDHeXd0UePTMzadIkTZkyRQMHDpQkde3aVQcPHtSsWbP05JNP1rqPn5+fW+5bAQCAWb311ls6ffp0ra+1aNGikatxnEeHmVOnTqlJk5qTR15eXnw1GwAAF7r++uvdXUK9eHSY6devn1566SVFRkaqc+fO2rlzp+bPn+/Q6msAAHB18+gw8+c//1l//OMf9fTTT6u8vFzh4eEaNWqU/vSnP7m7NAAA4CE8OswEBgYqKyurzosGAQAAePS3mQAAAK6EMAMAAEyNMAMAgJslJSVp3Lhxdb4+ffp0hYaGymKx6P33379ifwcOHJDFYrHdP6k2GzdulMVi0c8//+xwvZ7Go9fMAADgCo7cMqS+XH3LkeLiYs2YMUN5eXnq3r27mjdv7tL+7bFx40YtWLBAn332maxWq6KjozVp0iQNGjSoRrtNmzYpPT1de/bsUXh4uJ599lmlpqY2eH3MzAAA4MH2798vSUpJSVFYWJhbLgy7ZcsW/eY3v1Fubq6Kioo0bNgwDR48WH//+99tbUpKSpScnKyePXtq586deu6555SWlqbc3NwGr48wAwCAh8nPz1dwcLA6dOigfv36SZKaNGkii8UiSaqurtbMmTPVrl07+fn5KT4+Xvn5+Zftc926dYqJiVFAQIB69eqlAwcO2F3Pc889pxdeeEF33HGHOnbsqLS0NN1///3Ky8uztVm8eLEiIyOVlZWlTp06acSIERo2bJgyMzMdHwAHEWYAAPAgK1eu1KOPPqply5apqKhIOTk5kqTS0lKVlpZKkl555RXNmzdPmZmZKioqUp8+fdS/f3/t27ev1j4PHz6sAQMGKDk5WYWFhRoxYoSmTJlSrzorKipq3Org008/Ve/evWu06dOnj7Zt26aqqqp6vdeVEGYAAPAQixYtUmpqqtasWaOUlBQ1a9ZMISEhkqSwsDCFhYVJkjIzMzV58mQNHDhQsbGxmjNnjuLj4+u8Llt2drY6dOigBQsWKDY2VoMGDdKQIUOcrnP16tX6/PPPNXToUNu2srIyhYaG1mgXGhqqc+fO6YcffnD6vezBAmAAADxAbm6uvv/+e23evFkJCQl1trNarTp69KgSExNrbE9MTNSuXbtq3ae4uFjdu3e3naaSpB49ejhV58aNGzVkyBC9+eab6ty5c43Xft2/JBmGUet2V2NmBgAADxAfH6/WrVsrJyfHFgIup7bgUFdosKc/e2zatEn9+vXT/PnzNXjw4BqvhYWFqaysrMa28vJyeXt7q2XLli55/7oQZgAA8AAdO3ZUQUGB1qxZozFjxtTZLigoSOHh4dq8eXON7Vu2bFGnTp1q3ScuLk5bt26tse3i51eyceNGPfDAA5o9e7aeeuqpS17v0aOH1q9fX2PbRx99pG7dusnHx8eh93IUYQYAAA8RExOjgoIC5ebmXvYiepMmTdKcOXO0atUq7d27V1OmTFFhYaHGjh1ba/vU1FTt379f6enp2rt3r959910tWbLE7rouBJm0tDQ98sgjKisrU1lZmX766aca73Hw4EGlp6eruLhYf/nLX/T2229r4sSJdr+Ps1gzAwC46rn6QnYNKTY2Vhs2bFBSUpK8vLzUs2fPS9qkpaXJarVqwoQJKi8vV1xcnNauXavo6Oha+4yMjFRubq7Gjx+vRYsWKSEhQRkZGRo2bJhdNS1ZskSnTp3SrFmzNGvWLNv2u+++Wxs3bpQkRUVFad26dRo/frxee+01hYeH69VXX9Ujjzzi+CA4yGK46kSah7JarQoODlZFRYWCgoLcXQ5QK0euTvpyyOkGqyOwk/1f1dxdcsjutsUrwx2qo9NXxQ61ByTpzJkzKikpUVRUlPz9/d1dDuxwuc/Mkb/fnGYCAACmRpgBAOAa17dvXzVr1qzWR0ZGhrvLuyLWzAAAcI176623dPp07aewf32VX09FmAEA4Bp3/fXXu7uEeuE0EwDgqnKVf6/lquKqz4owAwC4Kly4MNupU6fcXAnsdeGzqu9F9TjNBAC4Knh5eSkkJETl5eWSpKZNmzb4PYHgHMMwdOrUKZWXlyskJEReXl716o8wAwC4aly4q/SFQAPPFhISYvvM6oMwAwC4algsFrVt21Zt2rRRVVWVu8vBZfj4+NR7RuYCwgwA4Krj5eXlsj+U8HwsAAYAAKZGmAEAAKZGmAEAAKZGmAEAAKbGAmCggbyWusHdJQDANYGZGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGqEGQAAYGpOhZmSkhJX1wEAAOAUp8LMjTfeqF69eumdd97RmTNnXF0TAACA3ZwKM7t27dItt9yiCRMmKCwsTKNGjdJnn33m6tokSUeOHNETTzyhli1bqmnTpoqPj9f27dsb5L0AAID5OBVmunTpovnz5+vIkSPKyclRWVmZ7rzzTnXu3Fnz58/Xv//9b5cUd+zYMSUmJsrHx0cffPCBvvzyS82bN08hISEu6R8AAJhfvRYAe3t76+GHH9Z7772nOXPmaP/+/Zo4caLatWunwYMHq7S0tF7FzZkzRxEREcrJyVFCQoJuuOEG3XPPPerYsWO9+gUAAFePeoWZbdu26emnn1bbtm01f/58TZw4Ufv379eGDRt05MgRpaSk1Ku4tWvXqlu3bvrv//5vtWnTRrfccovefPPNy+5TWVkpq9Va4wEAAK5e3s7sNH/+fOXk5Gjv3r1KTk7WsmXLlJycrCZNfslGUVFRev3113XTTTfVq7hvv/1W2dnZSk9P13PPPafPPvtMaWlp8vPz0+DBg2vdZ9asWZoxY0a93hfwZB+8P9Gh9n0fymygSgDAMzgVZrKzszVs2DANHTpUYWFhtbaJjIzU22+/Xa/iqqur1a1bN2VkZEiSbrnlFu3Zs0fZ2dl1hpmpU6cqPT3d9txqtSoiIqJedQAAAM/lVJjZt2/fFdv4+vrqySefdKZ7m7Zt2youLq7Gtk6dOik3N7fOffz8/OTn51ev9wUAAObh1JqZnJwc/fWvf71k+1//+lctXbq03kVdkJiYqL1799bY9vXXX6t9+/Yuew8AAGBuToWZ2bNnq1WrVpdsb9Omje2UkCuMHz9eW7duVUZGhr755hu9++67euONNzR69GiXvQcAADA3p8LMwYMHFRUVdcn29u3b69ChQ/Uu6oLbb79deXl5WrFihbp06aIXXnhBWVlZGjRokMveAwAAmJtTa2batGmjoqIi3XDDDTW279q1Sy1btnRFXTYPPvigHnzwQZf2CQAArh5OzcwMHDhQaWlpKigo0Pnz53X+/Hlt2LBBY8eO1cCBA11dIwAAQJ2cmpl58cUXdfDgQd1zzz3y9v6li+rqag0ePNila2YAAACuxKkw4+vrq1WrVumFF17Qrl27FBAQoK5du/ItIwAA0OicCjMXxMTEKCYmxlW1AAAAOMypMHP+/HktWbJE//znP1VeXq7q6uoar2/YsMElxQEAAFyJU2Fm7NixWrJkiR544AF16dJFFovF1XUBAADYxakws3LlSr333ntKTk52dT0AAAAOceqr2b6+vrrxxhtdXQsAAIDDnAozEyZM0CuvvCLDMFxdDwAAgEOcOs20efNmFRQU6IMPPlDnzp3l4+NT4/W//e1vLikOAADgSpwKMyEhIXr44YddXQsAAIDDnAozOTk5rq4DAADAKU6tmZGkc+fO6R//+Idef/11HT9+XJJ09OhRnThxwmXFAQAAXIlTMzMHDx7U/fffr0OHDqmyslL33XefAgMDNXfuXJ05c0aLFy92dZ0AAAC1cmpmZuzYserWrZuOHTumgIAA2/aHH35Y//znP11WHAAAwJU4/W2mTz75RL6+vjW2t2/fXkeOHHFJYQAAAPZwamamurpa58+fv2T7d999p8DAwHoXBQAAYC+nwsx9992nrKws23OLxaITJ05o2rRp3OIAAAA0KqdOMy1YsEC9evVSXFyczpw5o8cff1z79u1Tq1attGLFClfXCAAAUCenwkx4eLgKCwu1YsUK7dixQ9XV1Ro+fLgGDRpUY0EwAABAQ3MqzEhSQECAhg0bpmHDhrmyHgAAAIc4FWaWLVt22dcHDx7sVDEAAACOcirMjB07tsbzqqoqnTp1Sr6+vmratClhBgAANBqnvs107NixGo8TJ05o7969uvPOO1kADAAAGpXT92a6WHR0tGbPnn3JrA0AAEBDclmYkSQvLy8dPXrUlV0CAABcllNrZtauXVvjuWEYKi0t1cKFC5WYmOiSwgAAAOzhVJh56KGHajy3WCxq3bq1fvvb32revHmuqAsAAMAuToWZ6upqV9cBwAOkfvqK3W2LN45usDpumPK/drc9MPuBBqsDgDm4dM0MAABAY3NqZiY9Pd3utvPnz3fmLQAAAOziVJjZuXOnduzYoXPnzik2NlaS9PXXX8vLy0u33nqrrZ3FYnFNlQAAAHVwKsz069dPgYGBWrp0qZo3by7plwvpDR06VD179tSECRNcWiQAAEBdnFozM2/ePM2aNcsWZCSpefPmevHFF/k2EwAAaFROhRmr1arvv//+ku3l5eU6fvx4vYsCAACwl1Nh5uGHH9bQoUO1evVqfffdd/ruu++0evVqDR8+XAMGDHB1jQAAAHVyas3M4sWLNXHiRD3xxBOqqqr6pSNvbw0fPlwvv/yySwsEAAC4HKfCTNOmTbVo0SK9/PLL2r9/vwzD0I033qjrrrvO1fUBAABcVr0umldaWqrS0lLFxMTouuuuk2EYrqoLAADALk6FmR9//FH33HOPYmJilJycrNLSUknSiBEj+Fo2AABoVE6FmfHjx8vHx0eHDh1S06ZNbdsfe+wx5efnu6w4AACAK3FqzcxHH32kDz/8UO3atauxPTo6WgcPHnRJYQAAAPZwambm5MmTNWZkLvjhhx/k5+dX76IAAADs5VSYueuuu7Rs2TLbc4vFourqar388svq1auXy4oDAAC4EqdOM7388stKSkrStm3bdPbsWT377LPas2ePfvrpJ33yySeurhEAAKBOTs3MxMXFqaioSAkJCbrvvvt08uRJDRgwQDt37lTHjh1dXSMAAECdHJ6ZqaqqUu/evfX6669rxowZDVETAACA3RyemfHx8dEXX3whi8XSEPUAAAA4xKnTTIMHD9bbb7/t6loAAAAc5tQC4LNnz+qtt97S+vXr1a1bt0vuyTR//nyXFAcAAHAlDoWZb7/9VjfccIO++OIL3XrrrZKkr7/+ukYbTj8BAIDG5FCYiY6OVmlpqQoKCiT9cvuCV199VaGhoQ1SHAAAwJU4tGbm4rtif/DBBzp58qRLCwIAAHCEUwuAL7g43AAAADQ2h8KMxWK5ZE0Ma2QAAIA7ObRmxjAMDRkyxHYzyTNnzig1NfWSbzP97W9/c12FAAAAl+FQmHnyySdrPH/iiSdcWgwAAICjHAozOTk5DVUHAACAU+q1ABgAAMDdTBVmZs2aJYvFonHjxrm7FAAA4CFME2Y+//xzvfHGG/rNb37j7lIAAIAHMUWYOXHihAYNGqQ333xTzZs3d3c5AADAg5gizIwePVoPPPCA7r333iu2rayslNVqrfEAAABXL6fumt2YVq5cqR07dujzzz+3q/2sWbM0Y8aMBq4KV4vimzo51L7TV8UNVIn9NiS95uAepz2kDvtN+tn+to58hp0GHnWskOkVjrUH4BYePTNz+PBhjR07Vu+88478/f3t2mfq1KmqqKiwPQ4fPtzAVQIAAHfy6JmZ7du3q7y8XLfddptt2/nz5/Xxxx9r4cKFqqyslJeXV419/Pz8bFcoBgAAVz+PDjP33HOPdu/eXWPb0KFDddNNN2ny5MmXBBkAAHDt8egwExgYqC5dutTYdt1116lly5aXbAcAANcmj14zAwAAcCUePTNTm40bN7q7BAAA4EGYmQEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKZGmAEAAKbm7e4CAHt0XdrV7ra7n9xtd9sNSa85VMeG1A0OtfcEk34OcHcJpuXIz50jHPkZ1fRgxzqfXuFYe+AqwMwMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNcIMAAAwNY8OM7NmzdLtt9+uwMBAtWnTRg899JD27t3r7rIAAIAH8egws2nTJo0ePVpbt27V+vXrde7cOfXu3VsnT550d2kAAMBDeLu7gMvJz8+v8TwnJ0dt2rTR9u3bddddd7mpKgAA4Ek8OsxcrKKiQpLUokWLOttUVlaqsrLS9txqtTZ4XQAAwH1ME2YMw1B6erruvPNOdenSpc52s2bN0owZMxqxsqvc9GAH2lY0XB0OeC11g7tLgIcqXhnu2A5TG6aOrku72t12d8OUAFxVPHrNzK8988wzKioq0ooVKy7bburUqaqoqLA9Dh8+3EgVAgAAdzDFzMyYMWO0du1affzxx2rXrt1l2/r5+cnPz6+RKgMAAO7m0WHGMAyNGTNGeXl52rhxo6KiotxdEgAA8DAeHWZGjx6td999V2vWrFFgYKDKysokScHBwQoICHBzdQAAwBN49JqZ7OxsVVRUKCkpSW3btrU9Vq1a5e7SAACAh/DomRnDMNxdAgAA8HAePTMDAABwJYQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgat7uLsDsui7tanfb3U/ubsBKHDA92O6mXaMi7W7ryNG9lrrBgdZSql5xqD3gCu/NOtcg/T46teF+9TryO8mR4+v0VbH9RTjwO+aX9hWOtUfDc+Qz9IDPj5kZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaoQZAABgaqYIM4sWLVJUVJT8/f1122236V//+pe7SwIAAB7C48PMqlWrNG7cOP3hD3/Qzp071bNnT/Xt21eHDh1yd2kAAMADeHyYmT9/voYPH64RI0aoU6dOysrKUkREhLKzs91dGgAA8ADe7i7gcs6ePavt27drypQpNbb37t1bW7ZsqXWfyspKVVZW2p5XVFRIkqxWa4PUeP70ebvbNlQNDqs07G7aUMd3+uxJu9sCl3PivP0/o57i/GmL3W2tDvz/+kvf9o+HI2Pn0O8vB2uWp/xuxH848hk20Od34WfOMOyoxfBgR44cMSQZn3zySY3tL730khETE1PrPtOmTTMk8eDBgwcPHjyugsfhw4evmBc8embmAoul5r9iDMO4ZNsFU6dOVXp6uu15dXW1fvrpJ7Vs2bLOfVzJarUqIiJChw8fVlBQUIO/37WAMW0YjKvrMaYNg3F1PTOMqWEYOn78uMLDw6/Y1qPDTKtWreTl5aWysrIa28vLyxUaGlrrPn5+fvLz86uxLSQkpKFKrFNQUJDH/oCYFWPaMBhX12NMGwbj6nqePqbBwcF2tfPoBcC+vr667bbbtH79+hrb169frzvuuMNNVQEAAE/i0TMzkpSenq7f//736tatm3r06KE33nhDhw4dUmpqqrtLAwAAHsDjw8xjjz2mH3/8UTNnzlRpaam6dOmidevWqX379u4urVZ+fn6aNm3aJae64DzGtGEwrq7HmDYMxtX1rrYxtRiGPd95AgAA8EwevWYGAADgSggzAADA1AgzAADA1AgzAADA1Agzdvj444/Vr18/hYeHy2Kx6P3336/xumEYmj59usLDwxUQEKCkpCTt2bOnRpvKykqNGTNGrVq10nXXXaf+/fvru+++a8Sj8CyuGNM33nhDSUlJCgoKksVi0c8//9x4B+Ch6juuP/30k8aMGaPY2Fg1bdpUkZGRSktLs93j7Frlip/XUaNGqWPHjgoICFDr1q2VkpKir776qhGPwrO4Ykx/3bZv37619nOtccW4JiUlyWKx1HgMHDiwEY/CcYQZO5w8eVI333yzFi5cWOvrc+fO1fz587Vw4UJ9/vnnCgsL03333afjx4/b2owbN055eXlauXKlNm/erBMnTujBBx/UeRPeJM8VXDGmp06d0v3336/nnnuuscr2ePUd16NHj+ro0aPKzMzU7t27tWTJEuXn52v48OGNeRgexxU/r7fddptycnJUXFysDz/8UIZhqHfv3vwOqMeYXpCVldUot6sxA1eN68iRI1VaWmp7vP76641RvvOcvgvkNUqSkZeXZ3teXV1thIWFGbNnz7ZtO3PmjBEcHGwsXrzYMAzD+Pnnnw0fHx9j5cqVtjZHjhwxmjRpYuTn5zda7Z7KmTH9tYKCAkOScezYsUao1jzqO64XvPfee4avr69RVVXVkOWahqvGddeuXYYk45tvvmnIck2hPmNaWFhotGvXzigtLb2kn2uds+N69913G2PHjm3ESuuPmZl6KikpUVlZmXr37m3b5ufnp7vvvltbtmyRJG3fvl1VVVU12oSHh6tLly62NvgPe8YUjnN2XCsqKhQUFCRvb4+/xqZbODOuJ0+eVE5OjqKiohQREdFYpZqGvWN66tQp/e53v9PChQsVFhbmjlJNxZGf1eXLl6tVq1bq3LmzJk6cWOuMmCchzNTThZtgXnzjy9DQUNtrZWVl8vX1VfPmzetsg/+wZ0zhOGfG9ccff9QLL7ygUaNGNXh9ZuXIuC5atEjNmjVTs2bNlJ+fr/Xr18vX17fRajULe8d0/PjxuuOOO5SSktKo9ZmVveM6aNAgrVixQhs3btQf//hH5ebmasCAAY1aq6P4p5aLXHy+1jCMK57DtafNtcyZMcWV2TuuVqtVDzzwgOLi4jRt2rTGKs+07BnXQYMG6b777lNpaakyMzP16KOP6pNPPpG/v39jlmoalxvTtWvXasOGDdq5c6c7SjO1K/2sjhw50vbfXbp0UXR0tLp166YdO3bo1ltvbbQ6HcHMTD1dmNq8+F9g5eXltvQbFhams2fP6tixY3W2wX/YM6ZwnCPjevz4cd1///1q1qyZ8vLy5OPj02h1mo0j4xocHKzo6GjdddddWr16tb766ivl5eU1Wq1mYc+YbtiwQfv371dISIi8vb1tp0EfeeQRJSUlNWq9ZuHs79Zbb71VPj4+2rdvX4PWVx+EmXqKiopSWFiY1q9fb9t29uxZbdq0SXfccYekX77F4OPjU6NNaWmpvvjiC1sb/Ic9YwrH2TuuVqtVvXv3lq+vr9auXcuswRXU5+fVMAxVVlY2dImmY8+YTpkyRUVFRSosLLQ9JGnBggXKyclxR9kez9mf1T179qiqqkpt27ZtjDKdwmkmO5w4cULffPON7XlJSYkKCwvVokULRUZGaty4ccrIyFB0dLSio6OVkZGhpk2b6vHHH5f0y7/Ghg8frgkTJqhly5Zq0aKFJk6cqK5du+ree+9112G5VX3HVPrlXxdlZWW2fnbv3q3AwEBFRkaqRYsWjX5MnqC+43r8+HH17t1bp06d0jvvvCOr1Sqr1SpJat26tby8vNxyXO5W33H99ttvtWrVKvXu3VutW7fWkSNHNGfOHAUEBCg5Odldh+VW9R3TsLCwWhf9RkZGKioqqtGOw9PUd1z379+v5cuXKzk5Wa1atdKXX36pCRMm6JZbblFiYqK7DuvK3PdFKvO48NXfix9PPvmkYRi/fN1t2rRpRlhYmOHn52fcddddxu7du2v0cfr0aeOZZ54xWrRoYQQEBBgPPvigcejQITccjWdwxZhOmzat1j5ycnIa/4A8RH3Hta79JRklJSXuOSgPUN9xPXLkiNG3b1+jTZs2ho+Pj9GuXTvj8ccfN7766is3HZH7ueJ3wMXEV7PrPa6HDh0y7rrrLqNFixaGr6+v0bFjRyMtLc348ccf3XRE9rEYhmE0VFACAABoaKyZAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApkaYAQAApvb/4rGq0R6Pp3gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mses.plot(kind='hist', bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a800b",
   "metadata": {},
   "source": [
    "You can see from these stats as well as the histogram that each of these methods converge on a very similar estimate of the mean squared error.\n",
    "\n",
    "However, the out of bag estimate exhibits lower variance than each of the kfold methods.\n",
    "\n",
    "While tuning a model - those kinds of swings in the estimation of the model performance can have an influence on hyperparameter decisions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69e167",
   "metadata": {},
   "source": [
    "# OOB Validation is WAY Faster than KFold XVal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab57d8",
   "metadata": {},
   "source": [
    "At 20 folds, our kfold estimate of the MSE comparable variation to our OOB estimate - and it takes 20 times as long to compute!\n",
    "\n",
    "In general, you can think of OOB validation as only requiring \"1x\" computation while kfold cross validation requires \"kx\"- that is, it takes k times as long or k times as much compute.\n",
    "\n",
    "That can be a HUGE difference in compute time.\n",
    "\n",
    "If you want to squeeze all you can out of your model while tuning, out of bag is often a superior option - being either much more stable than comparably fast kfold estimates (though it's still more than twice as fast as 3-fold x-val), or an order of magnitude faster than comparably stable kfold estimates.\n",
    "\n",
    "The impact of this can't be overestimated - having your experiments run 2-20x faster can be transformative in terms of your ability to iterate on a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51354ac4",
   "metadata": {},
   "source": [
    "# Bonus 1: One more time!\n",
    "\n",
    "In addition, you'll probably want to retrain the model one more time after performing kfold x-val.  This is because your kfold models will each have only been trained on a subset of the data.  \n",
    "\n",
    "You could just use one of the models from one of the folds, but depending on how many folds you've chosen you might be missing out on e.g. 33%, 25%, 20% etc of the dataset. That's usually enough to make a difference.\n",
    "\n",
    "This isn't necessarily the case with OOB.  If you know what hyperparams you're using (or you have the model sitting around after training), it's already trained after having performed OOB validation - there's no need to train it again.  It's already been trained on all of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234d774",
   "metadata": {},
   "source": [
    "# Bonus 2: Its even more precise as you crank up the number of estimators\n",
    "\n",
    "As you add estimators, you get more \"out of bag folds\" so your OOB performance estimates become more precise.\n",
    "\n",
    "Adding estimators also linearly increases the training time - which makes the added speed of OOB methods that much more crucial when you're tuning a model with a large number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "235acc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ea5367d08e48fbb80672fbb334482d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padkins\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "C:\\Users\\padkins\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "C:\\Users\\padkins\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "C:\\Users\\padkins\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ffe619540e4cd49a6ca3ddb1fb09ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11077f645d9e47179c5493f03602688e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oob_16</th>\n",
       "      <th>oob_64</th>\n",
       "      <th>oob_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104.892203</td>\n",
       "      <td>104.096593</td>\n",
       "      <td>102.100955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.889410</td>\n",
       "      <td>103.769406</td>\n",
       "      <td>102.387141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.761226</td>\n",
       "      <td>103.107335</td>\n",
       "      <td>102.148795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.913874</td>\n",
       "      <td>103.906723</td>\n",
       "      <td>101.808575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.020240</td>\n",
       "      <td>103.632222</td>\n",
       "      <td>101.864493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106.482416</td>\n",
       "      <td>102.061029</td>\n",
       "      <td>102.014666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.738301</td>\n",
       "      <td>102.935395</td>\n",
       "      <td>101.523997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>109.016659</td>\n",
       "      <td>105.082479</td>\n",
       "      <td>101.723573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105.420502</td>\n",
       "      <td>103.368622</td>\n",
       "      <td>102.261296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>108.932833</td>\n",
       "      <td>102.831308</td>\n",
       "      <td>102.726787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oob_16      oob_64     oob_256\n",
       "0  104.892203  104.096593  102.100955\n",
       "1  105.889410  103.769406  102.387141\n",
       "2  108.761226  103.107335  102.148795\n",
       "3  107.913874  103.906723  101.808575\n",
       "4  106.020240  103.632222  101.864493\n",
       "5  106.482416  102.061029  102.014666\n",
       "6  108.738301  102.935395  101.523997\n",
       "7  109.016659  105.082479  101.723573\n",
       "8  105.420502  103.368622  102.261296\n",
       "9  108.932833  102.831308  102.726787"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def oob_vs_n_estimators():\n",
    "    n_experiment_rounds = 10\n",
    "    \n",
    "    oob_mses_16 = [oob_mse(dict(n_estimators=16)) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    oob_mses_64 = [oob_mse(dict(n_estimators=64)) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    oob_mses_256 = [oob_mse(dict(n_estimators=256)) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    \n",
    "    mses = pd.DataFrame(dict(oob_16=oob_mses_16, \n",
    "                             oob_64=oob_mses_64,\n",
    "                             oob_256=oob_mses_256\n",
    "                            ))\n",
    "    \n",
    "    return mses\n",
    "    \n",
    "mses = oob_vs_n_estimators()\n",
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3226b8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'standard deviation of mse estimate'}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mses.std().plot(kind='bar', title='standard deviation of mse estimate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b487b1e",
   "metadata": {},
   "source": [
    "# But wait ... there's more!\n",
    "\n",
    "There are even more benefits to using OOB predictions.  We'll potentially discuss those in a future article..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
