{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8846d03f",
   "metadata": {},
   "source": [
    "# The Hidden Validation Set You Might Not Be Using\n",
    "\n",
    "I love Random Forests. Really, I love all decision tree based models.  The concept of learning by partitioning is simple and intuitive and is easy to reason about when you’re trying to understand how a model might be “seeing” your data.\n",
    "\n",
    "For me, unless it’s not a good match for the dataset, a Random Forest is the way I like to start playing around with a dataset.\n",
    "\n",
    "One of the reasons is that some random forest implementations have a built-in validation set of sorts.  If you’re not familiar with “out of bag” validation, it’s an excellent addition to your ML development toolkit that I find is underutilized.  In fact – I almost never run into anybody else who regularly uses it!\n",
    "\n",
    "Check out this notebook in which we explore how out-of-bag validation can speed up your workflow and potentially even give you a more accurate estimate of model performance than your k-fold cross-validation at a fraction of the computational cost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa7671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0884dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = dict(n_jobs=-1, n_estimators=256, min_samples_leaf=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714bc33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.032432</td>\n",
       "      <td>-0.013066</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>-0.017611</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>-0.014728</td>\n",
       "      <td>-0.014885</td>\n",
       "      <td>-0.005247</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>-0.008661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007763</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>-0.017136</td>\n",
       "      <td>-0.025479</td>\n",
       "      <td>-0.038388</td>\n",
       "      <td>-0.032405</td>\n",
       "      <td>-0.004957</td>\n",
       "      <td>-0.005976</td>\n",
       "      <td>-0.016520</td>\n",
       "      <td>-1.007347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008624</td>\n",
       "      <td>-0.032773</td>\n",
       "      <td>-0.020031</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>-0.006798</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>-0.040737</td>\n",
       "      <td>0.025638</td>\n",
       "      <td>-0.004040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031387</td>\n",
       "      <td>-0.014356</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>16.710669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015039</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>0.031771</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.041739</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.015583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001197</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>-0.032698</td>\n",
       "      <td>-0.021573</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>-0.015747</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.021787</td>\n",
       "      <td>-4.883995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>-0.031028</td>\n",
       "      <td>-0.029758</td>\n",
       "      <td>-0.040502</td>\n",
       "      <td>0.029972</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.017631</td>\n",
       "      <td>-0.034498</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>-0.009699</td>\n",
       "      <td>-0.007910</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>-0.048658</td>\n",
       "      <td>-0.008468</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>-3.864474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>-0.012750</td>\n",
       "      <td>-0.013199</td>\n",
       "      <td>-0.006064</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.023851</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>-0.001793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>-0.000769</td>\n",
       "      <td>-0.037190</td>\n",
       "      <td>0.039113</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>-0.007129</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>-0.020894</td>\n",
       "      <td>6.945772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.032432 -0.013066  0.004673 -0.017611  0.035532 -0.014728 -0.014885   \n",
       "1  0.008624 -0.032773 -0.020031  0.020145 -0.006798  0.003736  0.023822   \n",
       "2 -0.015039  0.034703  0.031771  0.001136 -0.000144  0.041739 -0.010032   \n",
       "3  0.009395  0.024268 -0.031028 -0.029758 -0.040502  0.029972  0.011669   \n",
       "4  0.003794  0.009415  0.006692 -0.012750 -0.013199 -0.006064  0.015940   \n",
       "\n",
       "          7         8         9  ...        21        22        23        24  \\\n",
       "0 -0.005247  0.003580 -0.008661  ... -0.007763  0.016018 -0.017136 -0.025479   \n",
       "1 -0.040737  0.025638 -0.004040  ... -0.031387 -0.014356  0.001716  0.038014   \n",
       "2  0.005467  0.003280  0.015583  ... -0.001197  0.028461 -0.032698 -0.021573   \n",
       "3  0.017631 -0.034498  0.003571  ...  0.005521 -0.001306 -0.009699 -0.007910   \n",
       "4  0.023851  0.017628 -0.001793  ...  0.010429 -0.000769 -0.037190  0.039113   \n",
       "\n",
       "         25        26        27        28        29     target  \n",
       "0 -0.038388 -0.032405 -0.004957 -0.005976 -0.016520  -1.007347  \n",
       "1  0.016288  0.008245 -0.004310  0.001984  0.016031  16.710669  \n",
       "2  0.013873  0.024355 -0.015747  0.005714  0.021787  -4.883995  \n",
       "3  0.025553 -0.048658 -0.008468  0.045984  0.004110  -3.864474  \n",
       "4  0.005426 -0.007129  0.001969  0.004865 -0.020894   6.945772  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_toy_dataset(n_train):\n",
    "    # Generating an unbalanced dataset\n",
    "    X, y = make_regression(\n",
    "        n_samples=n_train,\n",
    "        n_features=30,\n",
    "        n_informative=5,\n",
    "        effective_rank=12,\n",
    "        tail_strength=0.5,\n",
    "        noise=10.0,\n",
    "        random_state=42\n",
    "    )\n",
    "    df = pd.DataFrame(X)\n",
    "    df.columns = df.columns.astype(str)\n",
    "    _X = df.columns\n",
    "    _y = 'target'\n",
    "    df[_y] = y\n",
    "    return df, _X, _y\n",
    "\n",
    "df, _X, _y = generate_toy_dataset(n_train=1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd2fa0",
   "metadata": {},
   "source": [
    "# Bootstrapping and the Out of Bag Sample\n",
    "\n",
    "By default in scikit-learn, the Random Forest Regressor uses boostrap sampling.  That is, if you feed in \"n\" samples, every decision tree in the forest is trained on \"n\" samples chosen with replacement from the original \"n\".  \n",
    "\n",
    "Since the sampling happens with replacement, there will almost always be some samples left out of training on each tree.  Those rows are described as being \"out of bag\".\n",
    "\n",
    "The \"out of bag\" sample is interesting because it has the properties of a randomly selected validation set.  For each estimator added to the forest we have a \"free\" validation set sitting there which can be used in a manner similar to other forms of validation like \"leave one out\" or \"k-fold cross validation\".\n",
    "\n",
    "# oob_prediction\n",
    "\n",
    "We can form a prediction for the out of bag samples simply by feeding them into the decision tree that was trained during the round in which they were left out of training.\n",
    "\n",
    "These predictions are generated for each estimator, so in general each sample will have many out-of-bag predictions.\n",
    "\n",
    "The standard way of producing a prediction from a random forest is to feed a sample into each decision tree, get a prediction from each, and then average all of the predictions together.In a similar way, we can form an \"out-of-bag prediction\" for each sample in the training set by averaging together all of the individual out-of-bag predictions for that sample.  \n",
    "\n",
    "Since a given sample was never involved in the training of the tree that produces its out of bag prediction, the out-of-bag prediction can provide an estimate of generalization to unseen samples. In fact, it can be proven that the out-of-bag prediction is in general a *slightly pessimistic* evaluation of generalization performance.\n",
    "\n",
    "# The oob_prediction is like having a \"free\" set of cross-validation predictions\n",
    "\n",
    "The best thing about the oob_prediction is that it comes \"for free\" (small computational cost) as long as you ask for it, simply by specifying \"oob_score=True\". \n",
    "\n",
    "Do that and train the model and you'll be given access to \"oob_prediction\" which you can use to compute out-of-bag statistics which are very similar to cross validation statistics.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4be54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=20, n_estimators=256, n_jobs=-1,\n",
       "                      oob_score=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestRegressor(oob_score=True, **rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a0b08",
   "metadata": {},
   "source": [
    "note: in what follows, we're specifically investigating OOB as an alternative to cross-validation within the context of bagging models like random forests and not boosting models, for which oob estimates of performance can also be obtained (but which don't have as desirable of properties necessarily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd2b55",
   "metadata": {},
   "source": [
    "# Compare oob to xval\n",
    "\n",
    "I'd like to argue that OOB Validation is simply generally better than KFold Cross Validation\n",
    "\n",
    "Why it's better:\n",
    "- it's easier and simpler to code up. \n",
    "- it's more precise (performance metric estimates have less variation)\n",
    "- train only 1 model instead of k models.  It's k times faster!  \n",
    "\n",
    "In addition, there are downstream tasks like stacking, calibration, and potentially more - which are easier to do with OOB predictions than with a kfold-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f3f3c",
   "metadata": {},
   "source": [
    "# The code is simpler than kfold\n",
    "\n",
    "The code is just easier to write.  I don't know about you - but for me there's always a little bit of mental overhead or boilerplate in setting up a kfold loop or using a cross-val convenience wrapper.  OOB just totally eliminates that.\n",
    "\n",
    "No loops, no cross-val wrappers - just a single extra param and you've got your OOB predictions ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f6e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oob_mse(additional_rf_params={}):\n",
    "    model = RandomForestRegressor(oob_score=True, **{**rf_params, **additional_rf_params})\n",
    "    P = model.fit(df[_X], df[_y]).oob_prediction_ #boom - one and done\n",
    "    return mean_squared_error(P, df[_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3299b5",
   "metadata": {},
   "source": [
    "### Compare to Kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da3b2e",
   "metadata": {},
   "source": [
    "Compare to using \"KFold\" + manually indexing folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f7ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def kfold_mse(n_folds):\n",
    "    mses = []\n",
    "    for train_index, val_index in KFold(n_splits=n_folds, random_state=None, shuffle=True).split(df):\n",
    "        X_train = df.loc[train_index, _X]\n",
    "        y_train = df.loc[train_index, _y]\n",
    "        X_val   = df.loc[val_index, _X]\n",
    "        y_val   = df.loc[val_index, _y]\n",
    "        model = RandomForestRegressor(oob_score=False, **rf_params)\n",
    "        P_val = model.fit(X_train, y_train).predict(X_val)\n",
    "        mses.append(mean_squared_error(P_val, y_val))\n",
    "    return np.mean(mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba2d18",
   "metadata": {},
   "source": [
    "There's a lot to track here in terms of indexing etc. \n",
    "\n",
    "To be fair, there are things you can do with this approach that you can't do with the OOB technique.  For example: stratified sampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43791230",
   "metadata": {},
   "source": [
    "### Compare to Xval Convenience Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115184a",
   "metadata": {},
   "source": [
    "Or compare to scikit-learn's cross validation convenience functions which can be less elegant and less flexible than the OOB approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b86ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "def sklearn_cv_mse(n_folds):\n",
    "    mse = make_scorer(mean_squared_error)\n",
    "    model = RandomForestRegressor(oob_score=False, **rf_params)\n",
    "    cv_results = cross_validate(model, df[_X], df[_y], cv=n_folds, scoring=mse) \n",
    "    return np.mean(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152fb6ce",
   "metadata": {},
   "source": [
    "In this example you need to remember to make your own \"mean_squared_error\" scorer using \"make_scorer\" or you have to feed in \"neg_mean_squared_error\" which results in the output score being negative.\n",
    "\n",
    "It's a bit awkward!  \n",
    "\n",
    "I went with making my own scorer to avoid any downstream effects from potentially forgetting to negate the output of cv_results['test_score'] (for example - accidentally selecting the worst model instead of the best model from a hyperparam search).\n",
    "\n",
    "Even the somewhat streamlined cross_validate convenience function isn't as clean, simple, and terse as the OOB validation method.\n",
    "\n",
    "It's not a huge difference on its own but efficiencies in code add up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c79fbe",
   "metadata": {},
   "source": [
    "# OOB Validation is more precise than kfold cross-validation\n",
    "\n",
    "Let's measure the precision of out of bag validation compared to kfold cross validation .\n",
    "\n",
    "We'll do this by repeatedly running en experiment in which we compute a validation statistic (mean squared error) and then analyze the variation of that statistic across repeated runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11f4fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af68f1ad02d243ce9b935709b09712fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cd67a97eab45e8b9b4e9b71a235988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43720336843c4e1182cba0f14a2a473c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5747814f0994a8ea8d64b9824bbfb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dc2d07df6946578bd6572f232b4883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def oob_vs_kfold():\n",
    "    n_experiment_rounds = 100\n",
    "    \n",
    "    oob_mses      = [oob_mse() for _ in tqdm(range(n_experiment_rounds))]\n",
    "    kfold_mses_3  = [kfold_mse(n_folds=3)  for _ in tqdm(range(n_experiment_rounds))]\n",
    "    kfold_mses_5  = [kfold_mse(n_folds=5)  for _ in tqdm(range(n_experiment_rounds))]\n",
    "    kfold_mses_10 = [kfold_mse(n_folds=10) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    kfold_mses_20 = [kfold_mse(n_folds=20) for _ in tqdm(range(n_experiment_rounds))]\n",
    "      \n",
    "    mses = pd.DataFrame(dict(oob=oob_mses, \n",
    "                             kfold_3=kfold_mses_3,\n",
    "                             kfold_5=kfold_mses_5,\n",
    "                             kfold_10=kfold_mses_10,\n",
    "                             kfold_20=kfold_mses_20\n",
    "                            ))\n",
    "    \n",
    "    return mses\n",
    "    \n",
    "mses = oob_vs_kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e424af1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oob</th>\n",
       "      <th>kfold_3</th>\n",
       "      <th>kfold_5</th>\n",
       "      <th>kfold_10</th>\n",
       "      <th>kfold_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.655721</td>\n",
       "      <td>102.324322</td>\n",
       "      <td>101.771559</td>\n",
       "      <td>101.712926</td>\n",
       "      <td>103.355493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.932552</td>\n",
       "      <td>101.985818</td>\n",
       "      <td>102.859353</td>\n",
       "      <td>102.679487</td>\n",
       "      <td>101.696226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.196427</td>\n",
       "      <td>102.804625</td>\n",
       "      <td>101.749743</td>\n",
       "      <td>101.721900</td>\n",
       "      <td>102.195220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.830217</td>\n",
       "      <td>103.121709</td>\n",
       "      <td>102.142025</td>\n",
       "      <td>102.446361</td>\n",
       "      <td>101.457749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102.632782</td>\n",
       "      <td>101.132519</td>\n",
       "      <td>101.631642</td>\n",
       "      <td>101.208073</td>\n",
       "      <td>101.584012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>102.309104</td>\n",
       "      <td>104.792745</td>\n",
       "      <td>101.627126</td>\n",
       "      <td>102.832689</td>\n",
       "      <td>101.708615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>102.740184</td>\n",
       "      <td>103.219084</td>\n",
       "      <td>102.123598</td>\n",
       "      <td>102.539162</td>\n",
       "      <td>101.445996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>102.645872</td>\n",
       "      <td>100.526466</td>\n",
       "      <td>102.710142</td>\n",
       "      <td>102.273256</td>\n",
       "      <td>101.981646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>101.835856</td>\n",
       "      <td>100.928727</td>\n",
       "      <td>102.407724</td>\n",
       "      <td>101.954604</td>\n",
       "      <td>102.354257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>101.700386</td>\n",
       "      <td>100.789548</td>\n",
       "      <td>101.953574</td>\n",
       "      <td>102.620575</td>\n",
       "      <td>102.056914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           oob     kfold_3     kfold_5    kfold_10    kfold_20\n",
       "0   101.655721  102.324322  101.771559  101.712926  103.355493\n",
       "1   101.932552  101.985818  102.859353  102.679487  101.696226\n",
       "2   102.196427  102.804625  101.749743  101.721900  102.195220\n",
       "3   101.830217  103.121709  102.142025  102.446361  101.457749\n",
       "4   102.632782  101.132519  101.631642  101.208073  101.584012\n",
       "..         ...         ...         ...         ...         ...\n",
       "95  102.309104  104.792745  101.627126  102.832689  101.708615\n",
       "96  102.740184  103.219084  102.123598  102.539162  101.445996\n",
       "97  102.645872  100.526466  102.710142  102.273256  101.981646\n",
       "98  101.835856  100.928727  102.407724  101.954604  102.354257\n",
       "99  101.700386  100.789548  101.953574  102.620575  102.056914\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3e93621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oob</th>\n",
       "      <th>kfold_3</th>\n",
       "      <th>kfold_5</th>\n",
       "      <th>kfold_10</th>\n",
       "      <th>kfold_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102.035529</td>\n",
       "      <td>102.356826</td>\n",
       "      <td>102.050711</td>\n",
       "      <td>101.946890</td>\n",
       "      <td>101.893951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.373525</td>\n",
       "      <td>1.074809</td>\n",
       "      <td>0.799415</td>\n",
       "      <td>0.563184</td>\n",
       "      <td>0.400006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.981443</td>\n",
       "      <td>99.803611</td>\n",
       "      <td>100.038969</td>\n",
       "      <td>100.211718</td>\n",
       "      <td>100.665326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103.031720</td>\n",
       "      <td>104.792745</td>\n",
       "      <td>103.664005</td>\n",
       "      <td>103.379787</td>\n",
       "      <td>103.355493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             oob     kfold_3     kfold_5    kfold_10    kfold_20\n",
       "mean  102.035529  102.356826  102.050711  101.946890  101.893951\n",
       "std     0.373525    1.074809    0.799415    0.563184    0.400006\n",
       "min   100.981443   99.803611  100.038969  100.211718  100.665326\n",
       "max   103.031720  104.792745  103.664005  103.379787  103.355493"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses.agg(['mean', 'std', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b229841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mses.plot(kind='hist', bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a800b",
   "metadata": {},
   "source": [
    "You can see from these stats as well as the histogram that each of these methods converge on a very similar estimate of the mean squared error.\n",
    "\n",
    "However, the out of bag estimate exhibits lower variance than each of the kfold methods.\n",
    "\n",
    "While tuning a model - those kinds of swings in the estimation of the model performance can have an influence on hyperparameter decisions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6bf43",
   "metadata": {},
   "source": [
    "# OOB Validation is WAY Faster than KFold XVal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8ff10",
   "metadata": {},
   "source": [
    "At 20 folds, our kfold estimate of the MSE comparable variation to our OOB estimate - and it takes 20 times as long to compute!\n",
    "\n",
    "In general, you can think of OOB validation as only requiring \"1x\" computation while kfold cross validation requires \"kx\"- that is, it takes k times as long or k times as much compute.\n",
    "\n",
    "That can be a HUGE difference in compute time.\n",
    "\n",
    "If you want to squeeze all you can out of your model while tuning, out of bag is often a superior option - being either much more stable than comparably fast kfold estimates (though it's still more than twice as fast as 3-fold x-val), or an order of magnitude faster than comparably stable kfold estimates.\n",
    "\n",
    "The impact of this can't be overestimated - having your experiments run 2-20x faster can be transformative in terms of your ability to iterate on a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be3b9a",
   "metadata": {},
   "source": [
    "# Bonus 1: One more time!\n",
    "\n",
    "In addition, you'll probably want to retrain the model one more time after performing kfold x-val.  This is because your kfold models will each have only been trained on a subset of the data.  \n",
    "\n",
    "You could just use one of the models from one of the folds, but depending on how many folds you've chosen you might be missing out on e.g. 33%, 25%, 20% etc of the dataset. That's usually enough to make a difference.\n",
    "\n",
    "This isn't necessarily the case with OOB.  If you know what hyperparams you're using (or you have the model sitting around after training), it's already trained after having performed OOB validation - there's no need to train it again.  It's already been trained on all of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234d774",
   "metadata": {},
   "source": [
    "# Bonus 2: Its even more precise as you crank up the number of estimators\n",
    "\n",
    "As you add estimators, you get more \"out of bag folds\" so your OOB performance estimates become more precise.  This also tracks along with generally better model performance.\n",
    "\n",
    "Adding estimators also linearly increases the training time - which makes the added speed of OOB methods that much more crucial when you're tuning a model with a large number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "235acc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ea5367d08e48fbb80672fbb334482d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padkins\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "C:\\Users\\padkins\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "C:\\Users\\padkins\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n",
      "C:\\Users\\padkins\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ffe619540e4cd49a6ca3ddb1fb09ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11077f645d9e47179c5493f03602688e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oob_16</th>\n",
       "      <th>oob_64</th>\n",
       "      <th>oob_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104.892203</td>\n",
       "      <td>104.096593</td>\n",
       "      <td>102.100955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.889410</td>\n",
       "      <td>103.769406</td>\n",
       "      <td>102.387141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.761226</td>\n",
       "      <td>103.107335</td>\n",
       "      <td>102.148795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.913874</td>\n",
       "      <td>103.906723</td>\n",
       "      <td>101.808575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.020240</td>\n",
       "      <td>103.632222</td>\n",
       "      <td>101.864493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106.482416</td>\n",
       "      <td>102.061029</td>\n",
       "      <td>102.014666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108.738301</td>\n",
       "      <td>102.935395</td>\n",
       "      <td>101.523997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>109.016659</td>\n",
       "      <td>105.082479</td>\n",
       "      <td>101.723573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105.420502</td>\n",
       "      <td>103.368622</td>\n",
       "      <td>102.261296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>108.932833</td>\n",
       "      <td>102.831308</td>\n",
       "      <td>102.726787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oob_16      oob_64     oob_256\n",
       "0  104.892203  104.096593  102.100955\n",
       "1  105.889410  103.769406  102.387141\n",
       "2  108.761226  103.107335  102.148795\n",
       "3  107.913874  103.906723  101.808575\n",
       "4  106.020240  103.632222  101.864493\n",
       "5  106.482416  102.061029  102.014666\n",
       "6  108.738301  102.935395  101.523997\n",
       "7  109.016659  105.082479  101.723573\n",
       "8  105.420502  103.368622  102.261296\n",
       "9  108.932833  102.831308  102.726787"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def oob_vs_n_estimators():\n",
    "    n_experiment_rounds = 10\n",
    "    \n",
    "    oob_mses_16 = [oob_mse(dict(n_estimators=16)) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    oob_mses_64 = [oob_mse(dict(n_estimators=64)) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    oob_mses_256 = [oob_mse(dict(n_estimators=256)) for _ in tqdm(range(n_experiment_rounds))]\n",
    "    \n",
    "    mses = pd.DataFrame(dict(oob_16=oob_mses_16, \n",
    "                             oob_64=oob_mses_64,\n",
    "                             oob_256=oob_mses_256\n",
    "                            ))\n",
    "    \n",
    "    return mses\n",
    "    \n",
    "mses = oob_vs_n_estimators()\n",
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3226b8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'standard deviation of mse estimate'}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mses.std().plot(kind='bar', title='standard deviation of mse estimate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b888a",
   "metadata": {},
   "source": [
    "# Why WOULDNT You Want to use OOB Validation?\n",
    "\n",
    "As always in machine learning: horses for courses!  You need to choose the right algorithm / approach for the task at hand.\n",
    "\n",
    "### Very large data? Even if you weren't planning on kfold cross-validation, you might still want to do OOB\n",
    "If you've got a large enough dataset, you might be considering using a simple validation set (e.g. 80/20 split) in which case you wouldn't be using kfold and you wouldn't necessarily see speed-up benefits from using OOB validation.  \n",
    "\n",
    "However I'd suggest that OOB Validation will still give you a more accurate and precise validation score in this context (because you're scoring on all of the data, not just 20%) AND at the end you'll have a model that's been trained on 100% of the data and not 80%.  And if you do decide to go back and train a model on the full dataset after doing an 80/20 validation - now we're back in a case in which the OOB method is 2x as fast!  It still looks like a clear winner. \n",
    "\n",
    "### Very small datasets - might want to stratify\n",
    "It may be the case that on small datasets (~100 samples) OOB's sampling doesn't give you a good estimate of the generalization error.  Neither may CV for that matter.  However, better sampling - like stratified sampling - may solve that issue for you.  The easiest way to perform stratified sampling using scikit-learn is to use a cross-validation procedure; so if you think you might need to do stratified sampling: maybe skip the OOB.   \n",
    "\n",
    "### There's a temporal component to the data\n",
    "If you need to do something like a back test - then an OOB validation score might not be what you want.  If you're forecasting ahead in time, you should probably do some sort of backtest.\n",
    "\n",
    "However I will say - I'd still personally want to see the OOB validation stats even if I was also getting stats from a back test!  They tell you something different about what kind of signal the model is capturing.  As long as you don't interpret the OOB results as represtentative of the quality of a forecast into the future, you'll be able to leverage these as additional information about what your model is learning (or is failing to learn).\n",
    "\n",
    "\n",
    "### If you're not using a bagging-based model like a Random Forest!\n",
    "If a Random Forest or a related model isn't the right choice for your problem - then of course OOB Validation may not be a good choice for you, as the best model for the problem may not even support OOB Validation.\n",
    "\n",
    "Although ... you can turn any model into a bagging model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b780967",
   "metadata": {},
   "source": [
    "# But wait ... there's more!\n",
    "\n",
    "There are even more benefits to using OOB predictions.  There are also benefits to creating bagged versions of models which traditionally don't use bagging. We'll potentially discuss those in a future article..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
